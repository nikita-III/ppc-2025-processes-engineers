#  Поразрядная сортировка для целых чисел с простым слиянием.

- Студент: Тимофеев Никита Сергеевич, группа 3823Б1ПР2
- Технологии: SEQ, MPI
- Вариант: 18

## 1. Введение
Применение технологии MPI и сравнение производительности программ с использованием MPI и последовательным выполнением, на примере задачи поразрядной сортировки для целых чисел с простым слиянием.
## 2. Постановка задачи
Задача: на вход программы подаётся массив целых чисел, необходимо реализовать поразрядную сортировку для целых чисел с простым слиянием.
Формат входных данных: ```std::vector<int>```
Формат выходных данных: ```std::vector<int>```
Необходимо создать две программы, одна из которых использует последовательное выполнение, другая - использует преимущества технологии MPI, затем сравнить их скорость.

## 3. Базовый алгоритм (Последовательный)
Алгоритм поразрядной сортировки с простым слиянием заключается в следующем: исходный массив разбивается на два массива: с неотрицательными и отрицательными числами. Для массива неотрицательных чисел вычисляется максимально возможное количество разрядов в числе, затем для каждого разряда выполняется следующее: создаётся двумерный массив, число строк в котором 10 (для произвольно системы счисления с основанием p - p строк, каждая строка отвечает числу в рассматриваемом на данной итерации разряде), и затем происходит проход по массиву неотрицательных чисел (время - количество элементов в нём, обозначим за n), и каждое число добавляется в конец той строки двумерного массива, номер которой совпадает со значением цифры в рассматриваемом разряде. Затем происходит проход по строкам двумерного массива (начиная с самой первой, нулевой), и все числа, начиная с первого в данной строке, записываются в результирующий массив (таким образом, числа идут в порядке возрастания цифры в разряде). Вся эта процедура выполняется для всех разрядов (максимально вохможного их числа), в результате получаем отсортированный массив неотрицательных чисел. Для отрицательных повторяется почти всё то же самое, с тем отличием, что числа берутся по модулю, и, так как в конце сортировки они будут идти по убыванию, то получившийся массив просто приписывается к отсортированному массиву неотрицательных слева в обратном порядке. В итоге получается отсортированный массив того же размера, что и переданный на вход изначально.

## 4. Схема распараллеливания
- Для MPI: распараллеливание ведётся следующим образом: нулевой процесс раздаёт данные остальным по такому принципу: выбирается k = (n / (количество процессов - 1)) + (n % (количество процессов - 1) > 0 ? 1 : 0) - иными словами, k >= n / (количество процессов - 1), и всегда положительно. Процессам, начиная с 1-го, рассылается по k элементов исходного массива, если на каком-то шаге осталось d != k элементов, они отсылаются последнему процессу. Далее процессы сортируют отосланные им подмассивы и отсылают их нулевому процессу, который собирает все части в единый результат с помощью алгоритма слияния и рассылает получившийся результат всем остальным. Слияние проводится следующим образом: берётся массив индексов по числу пресланных помассивов, сначала все элементы его равны нулю. Затем последодвательно просматриваются элементы во всех подмассивах с соответствующим индексом (в массиве индексов для каждого), и выбирается наименьшее из них, индекс для подмассива, где находится выбранное число, увеличивается на единицу. Выбраное число записывается в конец результирующего массива. Затем это повторяется, пока все индексы для каждого подмассива не будут указывать за пределы подмассивов. Таким образом, получается отсортированный массив того же размера, что и исходный.

## 5. Детали реализации
- Структура кода:
Есть классы ```TimofeevNRadixMergeMPI``` и ```TimofeevNRadixMergeSEQ```, там функция ```bool RunImpl()```. В последовательной и параллельной програмах реализованны алогритмы, описанные выше (Раздел 3. Базовый алгоритм и Раздел 4. Схема распараллеливания).
- Реализация предполагает, что если произошёл запуск с 1 процессом, всю работу выполняет единственный (нулевой) процесс.

## 6. Экспериментальная установка
- Аппаратное обеспечение / ОС: Intel(R) Core(TM) i7-3770, 8 ядер / 1 поток на ядро, 23.4 ГиБ ОЗУ, ОС: кубунту 24.04
- Инструментальная цепочка: gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0, clang-tidy-21, clang-format-21, тип сборки: Release
- Данные: тестовые данные для функциональных тестов находятся в файле tests/functional/main.cpp в виде списка типа ``` std::array<TestType, 11>```, тестовые данные для тестирования производительности представляют из себя пару массивов по 10000000 элементов каждый.

## 7. Результаты и выводы

### 7.1 Корректность
Корректность была проверена с помощью функциональных тестов. Обе программы корректно соритруют массивы (все тестовые данные есть в tests/functional/main.cpp)

### 7.2 Производительность
Время предоставлено для запусков с 1, 2, 3, 4, 7 и 8 процессами соответственно
| Mode         | Time, s        | Speedup | ProcNum |
|--------------|----------------|---------|---------|
| seq, task_run| 0.9072624683   | 1.00    |    1    |
| mpi, task_run| 0.8859208844   | 1.02    |    1    |
| seq, task_run| 0.9425448418   | 1.00    |    2    |
| mpi, task_run| 0.9135739002   | 1.03    |    2    |
| seq, task_run| 0.9370062828   | 1.00    |    3    |
| mpi, task_run| 0.5439644942   | 1.72    |    3    |
| seq, task_run| 0.9213790894   | 1.00    |    4    |
| mpi, task_run| 0.5628682704   | 1.64    |    4    |
| seq, task_run| 0.9011797592   | 1.00    |    7    |
| mpi, task_run| 0.1342757841   | 6.71    |    7    |
| seq, task_run| 0.9315690084   | 1.00    |    8    |
| mpi, task_run| 0.1313512301   | 7.10    |    8    |
Speedup для mpi = (seq time / mpi time)

## 8. Заключение
Были написаны две программы для сарвнения последовательного выполнения и mpi решения задачи поразрядной сортировки для целых чисел с простым слиянием. В результате применения технологии MPI программа ускорилась.

## Источники

1. Merging two lists - en.wikipedia.org. Ссылка: https://en.wikipedia.org/wiki/Merge_algorithm#Merging_two_lists